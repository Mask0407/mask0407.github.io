<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>Hadoop生态圈-Hive | 个人博客</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.0/css/all.min.css">
<link rel="shortcut icon" href="https://mask0407.github.io/favicon.ico?v=1593410445912">
<link rel="stylesheet" href="https://mask0407.github.io/styles/main.css">





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aos@2.3.4/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="


Hive引言
Hive的运行原理
Hive环境搭建
Hive基本操作
MetaStore的替换问题
Hive基础语法

1.HQL


2.表操作

1）管理表 (MANAGED_TABLE)
2)外部表
3) 分区表【优化查询】
4..." />
    <meta name="keywords" content="Hive,Hadoop,大数据" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://mask0407.github.io">
        <img src="https://mask0407.github.io/images/avatar.png?v=1593410445912" class="site-logo">
        <h1 class="site-title">个人博客</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      温故而知新
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://mask0407.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">Hadoop生态圈-Hive</h2>
            <div class="post-date">2020-06-29</div>
            
            <div class="post-content" v-pre>
              <p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#hive%E5%BC%95%E8%A8%80">Hive引言</a></li>
<li><a href="#hive%E7%9A%84%E8%BF%90%E8%A1%8C%E5%8E%9F%E7%90%86">Hive的运行原理</a></li>
<li><a href="#hive%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">Hive环境搭建</a></li>
<li><a href="#hive%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C">Hive基本操作</a></li>
<li><a href="#metastore%E7%9A%84%E6%9B%BF%E6%8D%A2%E9%97%AE%E9%A2%98">MetaStore的替换问题</a></li>
<li><a href="#hive%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95">Hive基础语法</a>
<ul>
<li><a href="#1hql">1.HQL</a></li>
</ul>
</li>
<li><a href="#2%E8%A1%A8%E6%93%8D%E4%BD%9C">2.表操作</a>
<ul>
<li><a href="#1%E7%AE%A1%E7%90%86%E8%A1%A8-managed_table">1）管理表 (MANAGED_TABLE)</a></li>
<li><a href="#2%E5%A4%96%E9%83%A8%E8%A1%A8">2)外部表</a></li>
<li><a href="#3-%E5%88%86%E5%8C%BA%E8%A1%A8%E4%BC%98%E5%8C%96%E6%9F%A5%E8%AF%A2">3) 分区表【优化查询】</a></li>
<li><a href="#4%E6%A1%B6%E8%A1%A8">4）桶表</a></li>
<li><a href="#5%E4%B8%B4%E6%97%B6%E8%A1%A8">5）临时表</a></li>
</ul>
</li>
<li><a href="#3-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5">3. 数据的导入</a>
<ul>
<li><a href="#1-%E5%9F%BA%E6%9C%AC%E5%AF%BC%E5%85%A5">1). 基本导入</a></li>
<li><a href="#2-%E9%80%9A%E8%BF%87as%E5%85%B3%E9%94%AE%E5%AE%8C%E6%88%90%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5">2). 通过as关键完成数据的导入</a></li>
<li><a href="#3-%E9%80%9A%E8%BF%87insert%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE">3). 通过insert的方式导入数据</a></li>
<li><a href="#4-hdfs%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE">4). hdfs导入数据</a></li>
<li><a href="#5-%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%95%B0%E6%8D%AE%E7%9A%84%E8%A6%86%E7%9B%96">5). 导入数据过程中数据的覆盖</a></li>
<li><a href="#6-%E9%80%9A%E8%BF%87hdfs%E7%9A%84api%E5%AE%8C%E6%88%90%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8A%E4%BC%A0">6). 通过HDFS的API完成文件的上传</a></li>
</ul>
</li>
<li><a href="#4-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%87%BA">4. 数据的导出</a>
<ul>
<li><a href="#1-sqoop">1). sqoop</a></li>
</ul>
</li>
<li><a href="#2-insert%E7%9A%84%E6%96%B9%E5%BC%8F">2). insert的方式</a>
<ul>
<li><a href="#3-%E9%80%9A%E8%BF%87hdfs%E7%9A%84api%E5%AE%8C%E6%88%90%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8B%E8%BD%BD">3). 通过HDFS的API完成文件的下载</a></li>
<li><a href="#4-%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%84%9A%E6%9C%AC%E7%9A%84%E6%96%B9%E5%BC%8F">4). 命令行脚本的方式</a></li>
</ul>
</li>
<li><a href="#5-hive%E6%8F%90%E4%BE%9B%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA%E7%9A%84%E5%B7%A5%E5%85%B7">5. Hive提供导入，导出的工具</a></li>
<li><a href="#6%E4%B8%8Emr%E7%9B%B8%E5%85%B3%E7%9A%84%E9%85%8D%E7%BD%AE">6.与MR相关的配置</a></li>
</ul>
</li>
</ul>
(Hive)</p>
<h2 id="hive引言">Hive引言</h2>
<ol>
<li>什么是Hive</li>
</ol>
<pre><code class="language-markdown">    hive是facebook开源，并捐献给了apache组织，作为apache组织的顶级项目。 hive.apache.org
    hive是一个基于大数据技术的数据仓库技术  DataWareHouse (数仓)
        数据库  DataBase
               数据量级小，数据价值高
        数据仓库 DataWareHouse
               数据体量大，数据价值低
    底层依附是HDFS,MapReduce
</code></pre>
<ol start="2">
<li>Hive的好处</li>
</ol>
<pre><code class="language-markdown">Hive让程序员应用时，书写SQL语句，最终由Hive把SQL语句转换成MapReduce运行，这样简化了程序员的工作。
</code></pre>
<h2 id="hive的运行原理">Hive的运行原理</h2>
<pre><code class="language-markdown">Hive是将大多数Hive SQL语句底层转换为MapReduce 运行Job作业来进行数据的处理
</code></pre>
<h2 id="hive环境搭建">Hive环境搭建</h2>
<pre><code class="language-markdown">1. linux服务器  ip 映射  主机名  关闭防火墙  关闭selinux  ssh免密登陆 jdk
2. 搭建hadoop环境
3. 安装Hive
   3.1 解压缩hive 
   3.2 hive_home/conf/hive-env.sh [改名]
       HADOOP_HOME=/opt/install/hadoop-2.5.2
       export HIVE_CONF_DIR=/opt/install/apache-hive-0.13.1-bin/conf
   3.2 hdfs创建2个目录
       /tmp
       /user/hive/warehouse
       bin/hdfs dfs -mkdir /tmp
       bin/hdfs dfs -mkdir /user/hive/warehouse
   3.3 启动hive
       bin/hive 
   3.4 jps
       runjar
</code></pre>
<h2 id="hive基本操作">Hive基本操作</h2>
<pre><code class="language-shell"># 创建数据库
create database [if not exists] test;
# 查看所有数据库
 show databases;
# 使用数据库
 use db_name;
# 删除空数据库 
 drop database db_name;
 drop database db_name cascade;
# 查看数据库的本质
 hive中的数据库 本质是 hdfs的目录 /user/hive/warehouse/test.db
  
# 查看当前数据库下的所有表
  show tables;
# 建表语句
  create table t_user(
    id int ,
    name string
   )row format delimited fields terminated by '\t';
# 查看表的本质
  hive中的表  本质是 hdfs的目录 /user/hive/warehouse/test.db/t_user
# 删除表
  drop table t_user;
  
# hive中向表导入数据
  load data local inpath '/root/hive/data' into table t_user;
# hive导入数据的本质
  load data local inpath '/root/hive/data' into table t_user;
  1. 导入数据 本质本质上就是 hdfs 上传文件
  bin/hdfs dfs -put /root/hive/data /user/hive/warehouse/test.db/t_user;
  2. 上传了重复数据，hive导数据时，会自动修改文件名
  3. 查询某一个张表时，Hive会把表中这个目录下所有文件的内容，整合查询出来
  
  
# SQL(类SQL 类似于SQL HQL Hive Query Language)
select * from t_user;
select id from t_user;
1. Hive把SQL转换成MapReduce (如果清洗数据 没有Reduce)
2. Hive在绝大多数情况下运行MR,但是在* limit操作时不运行MR
</code></pre>
<h2 id="metastore的替换问题">MetaStore的替换问题</h2>
<p>Hive中的MetaStore把HDFS对应结构，与表对应结果做了映射（对应）。但是默认情况下hive的metaStore应用的是derby数据库，只支持一个client访问。</p>
<ol>
<li>Hive中元数据库Derby替换成MySQL(Oracle)</li>
</ol>
<pre><code class="language-markdown">0. 删除hdfs /user/hive/warehouse目录，并重新建立
1. linux mysql
   yum -y install mysql-server
2. 启动mysql服务并设置管理员密码
   service mysqld start
   /usr/bin/mysqladmin -u root password '123456'
3. 打开mysql远程访问权限
   GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456';
   flush privileges;   
   use mysql 
   delete from user where host like 'hadoop%';
   delete from user where host like 'l%';
   delete from user where host like '1%';
   service mysqld restart
4. 创建conf/hive-site.xml
   mv hive-default.xml.template hive-site.xml
   hive-site.xml
   &lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
	  &lt;value&gt;jdbc:mysql://CentOSA:3306/metastore?createDatabaseIfNotExist=true&lt;/value&gt;
	  &lt;description&gt;the URL of the MySQL database&lt;/description&gt;
	&lt;/property&gt;

	&lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
	  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
	  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
	&lt;/property&gt;

	&lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
	  &lt;value&gt;root&lt;/value&gt;
	&lt;/property&gt;

	&lt;property&gt;
	  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
	  &lt;value&gt;123456&lt;/value&gt;
	&lt;/property&gt;
5. hive_home/lib 上传mysql driver jar包
</code></pre>
<h2 id="hive基础语法">Hive基础语法</h2>
<h3 id="1hql">1.HQL</h3>
<pre><code class="language-markdown">1. 基本查询
   select * from table_name # 不启动mr
   select id from table_name # 启动mr
2. 条件查询 where
   select id,name from t_users where name = 'mask1';
   2.1 比较查询  =  ！=  &gt;=  &lt;=
       select id,name from t_users where age &gt; 20;
   2.2 逻辑查询  and or  not
       select id,name,age from t_users where name = 'mask' or age&gt;30;
   2.3 谓词运算
       between and
       select name,salary from t_users where salary between 100 and 300;
       in
       select name,salary from t_users where salary in (100,300);
       is null
       select name,salary from t_users where salary is null;
       like
       select name,salary from t_users where name like 'mask%';
       select name,salary from t_users where name like 'mask__';
       select name,salary from t_users where name like 'mask%' and length(name) = 6;
3. 排序 order by [底层使用的是 map sort  group sort  compareto]
   select name,salary from t_users order by salary desc;
4. 去重 distinct
   select distinct(age) from t_users;
5. 分页 [Mysql可以定义起始的分页条目，但是Hive不可以]
   select * from t_users limit 3;  
6. 聚合函数（分组函数） count() avg() max() min() sum() 
   count(*)  count(id) 区别
7. group by
   select max(salary) from t_users group by age;
   规矩： select 后面只能写 分组依据和聚合函数 （Oracle报错，Mysql不报错，结果不对）
8. having 
   分组后，聚合函数的条件判断用having
   select max(salary) from t_users group by age having max(salary) &gt; 800;
9. hive不支持子查询 
10. hive内置函数 
    show functions 

    length(column_name)  获得列中字符串数据长度
    substring(column_name,start_pos,total_count)
    concat(col1,col2)
    to_data('yyyy-mm-dd')
    year(data) 获得年份
    month(data)
    date_add
    ....
    select year(to_date('1999-10-11')) ;
11. 多表操作
    inner join
    select e.name,e.salary,d.dname
    from t_emp as e
    inner join t_dept as d
    on e.dept_id = d.id;
    
    select e.name,e.salary,d.dname
    from t_emp as e
    left join t_dept as d
    on e.dept_id = d.id;
    
    select e.name,e.salary,d.dname
    from t_emp as e
    right join t_dept as d
    on e.dept_id = d.id;
    
    select e.name,e.salary,d.dname [mysql 不支持]
    from t_emp as e
    full join t_dept as d
    on e.dept_id = d.id; 
</code></pre>
<h2 id="2表操作">2.表操作</h2>
<h3 id="1管理表-managed_table">1）管理表 (MANAGED_TABLE)</h3>
<pre><code class="language-markdown">1. 基本管理表的创建
create table if not exists table_name(
column_name data_type,
column_name data_type
)row format delimited fields terminated by '\t' [location 'hdfs_path']

2. as 关键字创建管理表
create table if not exists table_name as select id,name from t_users [location ''];
表结构 由 查询的列决定，同时会把查询结果的数据 插入新表中

3. like 关键字创建管理表
create table if not exists table_name like t_users [location 'hdfs_path'];
表结构 和 like关键字后面的表 一致，但是没有数据是空表
</code></pre>
<p>细节操作</p>
<pre><code class="language-markdown">1. 数据类型 int string varchar char double float boolean  
2. location hdfs_path
   定制创建表的位置，默认是 /user/hive/warehouse/db_name.db/table_name
   create table t_mask(
   id,int
   name,string
   )row format delimited fields terminated by '\t' stored as textfile location /xiaohei ;
   启示：日后先有hdfs目录，文件，在创建表进行操作。
3. 查看hive表结构的命令
   desc table_name        describe table_name
   desc extended table_name
   desc formatted table_name 
</code></pre>
<h3 id="2外部表">2)外部表</h3>
<pre><code class="language-markdown">1. 基本
create external table if not exists table_name(
id int,
name string
) row delimited fields terminated by '\t' stored as textfile [location 'hdfs_path'];
2. as 
create external table if not exists table_name as select id,name from t_users [location ''];
3. like
create external table if not exists table_name like t_users [location 'hdfs_path'];
</code></pre>
<pre><code class="language-markdown">4. 管理表和外部表的区别
drop table t_users_as; 删除管理表时，直接删除metastore,同时删除hdfs的目录和数据文件
drop table t_user_ex;  删除外部表时，删除metastore的数据。
5. 外部表与管理表使用方式的区别
</code></pre>
<h3 id="3-分区表优化查询">3) 分区表【优化查询】</h3>
<p>分区表是为了提高条件查询时的效率</p>
<pre><code class="language-markdown">create table t_user_part(
id int,
name string,
age int,
salary int)partitioned by (data string) row format delimited fields terminated by '\t';

load data local inpath '/root/data15' into table t_user_part partition (date='15');
load data local inpath '/root/data16' into table t_user_part partition (date='16');

select * from t_user_part  全表数据进行的统计

select id from t_user_part where data='15' and age&gt;20;
</code></pre>
<h3 id="4桶表">4）桶表</h3>
<h3 id="5临时表">5）临时表</h3>
<h2 id="3-数据的导入">3. 数据的导入</h2>
<h3 id="1-基本导入">1). 基本导入</h3>
<pre><code class="language-markdown">   load data local inpath 'local_path' into table table_name
</code></pre>
<h3 id="2-通过as关键完成数据的导入">2). 通过as关键完成数据的导入</h3>
<pre><code class="language-markdown">   建表的同时，通过查询导入数据
   create table if not exists table_name as select id,name from t_users
</code></pre>
<h3 id="3-通过insert的方式导入数据">3). 通过insert的方式导入数据</h3>
<pre><code class="language-markdown">   #表格已经建好，通过查询导入数据。
   create table t_users_like like t_users;
   
   insert into table t_users_like select id,name,age,salary from t_users;
</code></pre>
<h3 id="4-hdfs导入数据">4). hdfs导入数据</h3>
<pre><code class="language-markdown">   load data inpath 'hdfs_path' into table table_name
</code></pre>
<h3 id="5-导入数据过程中数据的覆盖">5). 导入数据过程中数据的覆盖</h3>
<pre><code class="language-markdown">   load data inpath 'hdfs_path' overwrite into table table_name
   本质 把原有表格目录的文件全部删除，再上传新的
</code></pre>
<h3 id="6-通过hdfs的api完成文件的上传">6). 通过HDFS的API完成文件的上传</h3>
<pre><code class="language-markdown">   bin/hdfs dfs -put /xxxx  /user/hive/warehouse/db_name.db/table_name
</code></pre>
<h2 id="4-数据的导出">4. 数据的导出</h2>
<h3 id="1-sqoop">1). sqoop</h3>
<pre><code class="language-markdown">     hadoop的一种辅助工具  HDFS/Hive  &lt;------&gt; RDB (MySQL,Oracle)
</code></pre>
<h2 id="2-insert的方式">2). insert的方式</h2>
<pre><code class="language-markdown">      #xiaohei一定不能存在，自动创建
      insert overwrite 【local】 directory '/root/xiaohei' select name from t_user; 
</code></pre>
<h3 id="3-通过hdfs的api完成文件的下载">3). 通过HDFS的API完成文件的下载</h3>
<pre><code class="language-markdown">      bin/hdfs dfsd -get /user/hive/warehouse/db_name.db/table_name /root/xxxx
</code></pre>
<h3 id="4-命令行脚本的方式">4). 命令行脚本的方式</h3>
<pre><code class="language-markdown">      bin/hive --database 'test' -f /root/hive.sql &gt; /root/result
</code></pre>
<h2 id="5-hive提供导入导出的工具">5. Hive提供导入，导出的工具</h2>
<pre><code class="language-markdown">      1. export 导出
      	export table tb_name to 'hdfs_path'
      2. import 导入
      	import table tb_name from 'hdfs_path'
</code></pre>
<h2 id="6与mr相关的配置">6.与MR相关的配置</h2>
<pre><code class="language-xml">#与MR相关的参数
Map --&gt; Split  ---&gt; Block 
#reduce相关个数
mapred-site.xml
&lt;property&gt;
     &lt;name&gt;mapreduce.job.reduces&lt;/name&gt;
     &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
hive-site.xml
&lt;!--1G--&gt;
&lt;property&gt;
	  &lt;name&gt;hive.exec.reducers.bytes.per.reducer&lt;/name&gt;
	  &lt;value&gt;1000000000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;hive.exec.reducers.max&lt;/name&gt;
     &lt;value&gt;999&lt;/value&gt;
&lt;/property&gt;
</code></pre>

            </div>
            
              <div class="tag-container">
                
                  <a href="https://mask0407.github.io/yn_9TWp8Z/" class="tag">
                    Hive
                  </a>
                
                  <a href="https://mask0407.github.io/mWPQYQko7/" class="tag">
                    Hadoop
                  </a>
                
                  <a href="https://mask0407.github.io/1ffDVERZml/" class="tag">
                    大数据
                  </a>
                
              </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://mask0407.github.io/hive00/">
                  <h3 class="post-title">
                    Hive安装(超详细)
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/aos@2.3.4/dist/aos.min.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
