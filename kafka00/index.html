<html>

<head>
	<script src="../../prism.js"></script>
	<link href="../../prism.css" rel="stylesheet" />
	<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<title>个人博客</title>
<link rel="shortcut icon" href="https://mask0407.github.io/favicon.ico?v=1593419268990">
<script src="../../prism.js" ></script>
<link href="../../prism.css" rel="stylesheet" />
<link href="../../snow.css" rel="stylesheet" />
<link rel="stylesheet" href="https://mask0407.github.io/styles/main.css">
<meta name="description" content="温故而知新" />
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>

<link rel="stylesheet" href="/media/fonts/iconfont.css">
<link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>

</head>

<body>
	


<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>
<div class="snow"></div>

	<div class="head-top-line"></div>
	<div class="header-box">
		<header class="header">

	<div class="blog-header" id="header">
		<div class="section-layout-wrapper">
			<div class="site-meta">
				<div class="nav-toggle" id="nav_toggle">
					<div class="toggle-box">
						<div class="line line-top"></div>
						<div class="line line-center"></div>
						<div class="line line-bottom"></div>
					</div>
				</div>
				<div class="site-title">
					<a href="/" class="brand">
						<span>个人博客</span>
					</a>
				</div>
				<p class="subtitle"></p>
				<nav class="site-nav" id="site_nav">
					
					<li class="nav-item ">
						<a href="/">
							<!-- <i class="iconfont icon-home"></i> -->
							首页
						</a>
					</li>
					
					<li class="nav-item ">
						<a href="/archives">
							<!-- <i class="iconfont icon-home"></i> -->
							归档
						</a>
					</li>
					
					<li class="nav-item ">
						<a href="/tags">
							<!-- <i class="iconfont icon-home"></i> -->
							标签
						</a>
					</li>
					
					<li class="nav-item ">
						<a href="/post/about">
							<!-- <i class="iconfont icon-home"></i> -->
							关于
						</a>
					</li>
					
				</nav>
				<input type="serch" id="serch" placeholder="搜索其实很简单">
			</div>

		</div>
	</div>
<!-- <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?3e11339a177ba7e34848b1f198c46e5c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script> -->


</header>
<script type="text/javascript">

	let showNav = true;

	let navToggle = document.querySelector('#nav_toggle'),
		siteNav = document.querySelector('#site_nav');

	function navClick() {
		navToggle.classList.toggle('nav-toggle-active');
		siteNav.classList.toggle('nav-menu-active');
	}

	navToggle.addEventListener('click', navClick);  
</script>
	</div>
	<div class="main-continer">
		<div class="section-layout">
			<div class="section-layout-wrapper">

				<!-- <div class="section-box"> -->
				<div class="section post">
					<section class="section-items">
						<div class="article-box">
    <header class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://mask0407.github.io/kafka00/">
      一篇文章读懂Kafka消息队列
    </a>
  </h1>
  <div class="post-meta">
    <span class="meta-item">
      <i class="iconfont icon-calendar_empty"></i>
      <span class="pc-show">发布于</span>
      <span>2020-06-29</span>
    </span>
    
      <span class="meta-item">
        <span class="post-meta-divider">|</span>
        <i class="iconfont icon-folder_open_alt"></i>
        <span class="pc-show">分类于</span>
        
          
            <a href="https://mask0407.github.io/wCHLQOml4/">
              <span>Kafka</span>
            </a>、
          
        
          
            <a href="https://mask0407.github.io/mWPQYQko7/">
              <span>Hadoop</span>
            </a>、
          
        
          
            <a href="https://mask0407.github.io/1ffDVERZml/">
              <span>大数据</span>
            </a>
          
        
      </span>
    
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="iconfont icon-time"></i>
      <span>29分钟</span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="iconfont icon-keyboard"></i>
      <span class="pc-show">5949字数</span>
    </span>
  </div>
</header>
</div>
						<div class="post-body" id="post_body">
							<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%A6%82%E5%BF%B5">消息队列的概念</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90">使用消息队列的场景分析</a>
<ul>
<li><a href="#%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81">异步消息发送：</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E9%97%B4%E8%A7%A3%E8%80%A6%E5%90%88">系统间解耦合</a></li>
</ul>
</li>
<li><a href="#kafka-%E6%9E%B6%E6%9E%84">Kafka 架构</a></li>
<li><a href="#kafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85">Kafka集群安装</a>
<ul>
<li><a href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">准备工作</a></li>
<li><a href="#%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4%E7%A1%AE%E4%BF%9Dkafka%E9%9B%86%E7%BE%A4%E7%9A%84%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C">安装Zookeeper集群确保Kafka集群的正常运行</a></li>
<li><a href="#kafka%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4">Kafka安装步骤</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1">启动服务</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95">测试</a></li>
</ul>
</li>
<li><a href="#topic-%E5%92%8C-%E6%97%A5%E5%BF%97">Topic 和 日志</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85">生产者</a></li>
<li><a href="#%E6%B6%88%E8%B4%B9%E8%80%85">消费者</a></li>
<li><a href="#topic%E7%AE%A1%E7%90%86%E7%AF%87ddl">Topic管理篇（DDL）</a>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BAtocpic">创建Tocpic</a></li>
<li><a href="#topic%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF">Topic详细信息</a></li>
<li><a href="#%E5%88%A0%E9%99%A4topic">删除Topic</a></li>
<li><a href="#topic%E5%88%97%E8%A1%A8">Topic列表</a></li>
</ul>
</li>
<li><a href="#kafka-api%E5%AE%9E%E6%88%98jdk18">Kafka API实战(JDK1.8+)</a>
<ul>
<li><a href="#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8">快速入门</a>
<ul>
<li><a href="#maven%E4%BE%9D%E8%B5%96">Maven依赖</a></li>
<li><a href="#%E5%BC%95%E5%85%A5log4jproperies">引入log4j.properies</a></li>
<li><a href="#%E5%9C%A8windos%E9%85%8D%E7%BD%AE%E4%B8%BB%E6%9C%BA%E5%90%8D%E5%92%8Cip%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB">在Windos配置主机名和IP映射关系</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85-2">生产者</a></li>
<li><a href="#%E6%B6%88%E8%B4%B9%E8%80%85-2">消费者</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8E%A7%E5%88%B6">读取数据偏移量控制</a></li>
<li><a href="#%E6%8C%87%E5%AE%9A%E6%B6%88%E8%B4%B9%E5%88%86%E5%8C%BA">指定消费分区</a></li>
<li><a href="#kafka%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6object">Kafka发送/接收Object</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7">生产者幂等性</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%89%B9%E9%87%8F%E5%8F%91%E9%80%81">生产者批量发送</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1">生产者事务</a>
<ul>
<li><a href="#%E5%8F%AA%E6%9C%89%E7%94%9F%E4%BA%A7%E8%80%85">只有生产者</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85">生产者&amp;消费者</a></li>
</ul>
</li>
<li><a href="#springboot%E6%95%B4%E5%90%88kafka">SpringBoot整合Kafka</a></li>
</ul>
</li>
</ul>
(Kafka 基础篇)</p>
<h2 id="消息队列的概念">消息队列的概念</h2>
<p>可以用于系统间通讯的一个组件-middle ware（中间件），该组件可以用于做消息缓冲的中间件（持久化）解决一些 并发处理、数据库缓冲等实现对高并发的业务场景的削峰填谷。</p>
<h2 id="使用消息队列的场景分析">使用消息队列的场景分析</h2>
<h3 id="异步消息发送">异步消息发送：</h3>
<blockquote>
<p>使用Kafka MQ功能实现模块间异步通信，把一些费时的操作交给额外的服务或者设备去执行，这样可以提升系统运行效率，加速连接释放的速度，例如：用户注册模块，在用户注册成功后，业务系统需要给用户发送一个通知短信，通知用户登录邮箱去激活刚注册的用户信息。这种业务场景如图所示，因为短信通知和邮件发送是一个比较耗时的操作，所以在这里没必要将短信和邮件发送作为注册模块的流程，使用Message Queue功能可以将改业务和主业务注册分离，这样可以缩短用户浏览器和服务建立的链接时间，同时也能满足发送短信和邮件的业务。</p>
</blockquote>
<h3 id="系统间解耦合">系统间解耦合</h3>
<blockquote>
<p>①在某些高吞吐的业务场景下，可能会出现在某一个时间段系统负载写入的负载压力比较大，短时间有大量的数据需要持久化到数据库中，但是由于数据的持久化需要数据库提供服务，由于传统的数据库甚至一些NoSQL产品也不能很好的解决高并发写入，因为数据库除去要向用户提供链接之外，还需要对新来的数据做持久化，这就需要一定的时间才能将数据落地到磁盘。因此在高并发写入的场景，就需要用户集成Message Queue在数据库前作为缓冲队列。在队列的另一头只需要程序有条不紊的将数据写入到数据库即可，这就保证无论外界写入压力有多么大都可以借助于Message Queue缓解数据库的压力。</p>
</blockquote>
<blockquote>
<p>②Message Queue除了解决对数据缓冲的压力之外，还可以充当业务系统的中间件（Middleware）作为系统服务间解耦的组件存在，例如上图所示订单模块和库存模块中就可以使用Message Queue作为缓冲队列实现业务系统服务间的解耦，也就意味着即使服务在运行期间库存系统宕机也并不会影响订单系统的正常运行。</p>
</blockquote>
<h2 id="kafka-架构">Kafka 架构</h2>
<p>Kafka集群以Topic形式负责管理集群中的Record，每一个Record属于一个Topic。底层Kafka集群通过日志分区形式持久化Record。在Kafka集群中，Topic的每一个分区都一定会有1个Borker担当该分区的Leader，其他的Broker担当该分区的follower（取决于分区的副本因子）。一旦对应分区的Lead宕机，kafka集群会给当前的分区指定新的Borker作为该分区的Leader。分区的Leader的选举是通过Zookeeper一些特性实现的，这里就不在概述了。Leader负责对应分区的读写操作，Follower负责数据备份操作。<br>
<img src="https://img-blog.csdnimg.cn/20190724085841326.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L00yODM1OTIzMzg=,size_16,color_FFFFFF,t_70" alt="Kafka架构图" loading="lazy"></p>
<h2 id="kafka集群安装">Kafka集群安装</h2>
<h3 id="准备工作">准备工作</h3>
<p>准备三台主机名分别为CentOSA|CentOSB|CentOSC的Linux系统主机<br>
分别关闭防火墙、相互做主机名映射、校对物理时钟、安装配置JDK8</p>
<h3 id="安装zookeeper集群确保kafka集群的正常运行">安装Zookeeper集群确保Kafka集群的正常运行</h3>
<pre><code class="language-shell">tar -zxf zookeeper-3.4.6.tar.gz -C /usr/
mkdir /root/zkdata

#分别在三台机器执行以下命令
echo 1 &gt;&gt; /root/zkdata/myid
echo 2 &gt;&gt; /root/zkdata/myid
echo 3 &gt;&gt; /root/zkdata/myid

touch /usr/zookeeper-3.4.6/conf/zoo.cfg
vim /usr/zookeeper-3.4.6/conf/zoo.cfg
</code></pre>
<p>zoo.cfg</p>
<pre><code class="language-properties">tickTime=2000
dataDir=/root/zkdata
clientPort=2181
initLimit=5
syncLimit=2

server.1=CentOSA:2887:3887
server.2=CentOSB:2887:3887
server.3=CentOSC:2887:3887
</code></pre>
<p>启动zookeeper|查看zookeeper当前状态</p>
<pre><code class="language-shell">/usr/zookeeper-3.4.6/bin/zkServer.sh start zoo.cfg
/usr/zookeeper-3.4.6/bin/zkServer.sh status zoo.cfg
</code></pre>
<h3 id="kafka安装步骤">Kafka安装步骤</h3>
<ul>
<li>下载Kafka服务安装包http://archive.apache.org/dist/kafka/2.2.0/kafka_2.11-2.2.0.tgz</li>
</ul>
<pre><code class="language-shell">tar -zxf kafka_2.11-2.2.0.tgz -C /usr
vim /usr/kafka_2.11-2.2.0/config/server.properties
############################# Server Basics #############################
broker.id=[0|1|2]  #三台机器分别 0/1/2
############################# Socket Server Settings #############################
listeners=PLAINTEXT://CentOS[A|B|C]:9092 #三台机器分别A、B、C
############################# Log Basics #############################
# A comma separated list of directories under which to store log files
log.dirs=/usr/kafka-logs
############################# Zookeeper #############################
zookeeper.connect=CentOSA:2181,CentOSB:2181,CentOSC:2181
</code></pre>
<blockquote>
<p>注：此配置只能使用主机名访问 如需IP访问  将<code>listeners=PLAINTEXT://CentOS[A|B|C]:9092 #三台机器分别A、B、C</code><br>
改为<br>
<code>advertised.listeners=PLAINTEXT://x.x.x.x:9092</code></p>
</blockquote>
<h3 id="启动服务">启动服务</h3>
<pre><code class="language-shell">cd /usr/kafka_2.11-2.2.0/
./bin/kafka-server-start.sh -daemon config/server.properties
</code></pre>
<h3 id="测试">测试</h3>
<ul>
<li><strong>创建topic</strong></li>
</ul>
<pre><code class="language-shell">./bin/kafka-topics.sh --zookeeper CentOSA:2181,CentOSB:2181,CentOSC:2181 --create --topic topic01 --partitions 3 --replication-factor 3
</code></pre>
<ul>
<li><strong>消费者</strong></li>
</ul>
<pre><code class="language-shell">./bin/kafka-console-consumer.sh  --bootstrap-server CentOSA:9092,CentOSB:9092,CentOSC:9092 --topic topic01
</code></pre>
<ul>
<li><strong>生产者</strong></li>
</ul>
<pre><code class="language-shell">./bin/kafka-console-producer.sh --broker-list CentOSA:9092,CentOSB:9092,CentOSC:9092 --topic topic01
</code></pre>
<h2 id="topic-和-日志">Topic 和 日志</h2>
<p>Kafka集群是通过日志形式存储Topic中的Record，Record会根据分区策略计算得到的分区数存储到相应分区的文件中。每个分区都是一个有序的，不可变的记录序列，不断附加到结构化的commit-log中。每个分区文件会为Record进去分区的顺序进行编排。每一个分区中的Record都有一个id，该id标示了该record进入分区的先后顺序，通常将该id称为record在分区中的offset偏移量从0开始，依次递增。<br>
<img src="https://img-blog.csdnimg.cn/20190724190339421.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L00yODM1OTIzMzg=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<ul>
<li>
<p>Kafka集群持久地保留所有已发布的记录 - 无论它们是否已被消耗 - 使用可配置的保留时间。例如，如果保留策略设置为2天，则在发布记录后的2天内，它可供使用，之后将被丢弃以释放空间。Kafka的性能在数据大小方面实际上是恒定的，因此长时间存储数据不是问题。</p>
</li>
<li>
<p>事实上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移或位置。这种offset由消费者控制：通常消费者在读取记录时会线性地增加其偏移量，但事实上，由于消费者控制位置，它可以按照自己喜欢的任何顺序消费记录。例如，消费者可以重置为较旧的偏移量以重新处理过去的数据，或者跳到最近的记录并从“现在”开始消费。</p>
</li>
</ul>
<h2 id="生产者">生产者</h2>
<p>生产者负责发送Record到Kafka集群中的Topic中。在发布消息的时候，首先先计算Record分区计算方案有三种：</p>
<blockquote>
<p>①如果用户没有指定分区但是指定了key信息，生产者会根据<code>hash（key）%分区数</code>计算该Record所属分区信息。<br>
②如果生产者在发送消息的时候并没有key，也没有指定分区数，生产者会使用<strong>轮训策略</strong>选择分区信息。<br>
③如果指定了分区信息，就按照指定的分区信息选择对应的分区；当分区参数确定以后生产者会找到相应分区的Leader节点将Record记录写入到Topic日志存储分区中。</p>
</blockquote>
<h2 id="消费者">消费者</h2>
<p>消费者作为消息的消费放，消费者对Topic中消息的消费方式是以<strong>Group</strong>为单位进行消费，Kafka服务器会自动的按照组内和组间对消费者消费的分区进行协调。<br>
<img src="https://img-blog.csdnimg.cn/2019072419112678.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L00yODM1OTIzMzg=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" loading="lazy"></p>
<ul>
<li>组内<code>均分分区</code>，确保一个组内的消费者不可重复消费分区中的数据，一般来说一个组内的消费者实例对的数目应该小于或者等于分区数目。</li>
<li>组间<code>广播形式</code>消费，确保所有组都可以拿到当前Record。组间数据之间可以保证对数据的独立消费。</li>
</ul>
<h2 id="topic管理篇ddl">Topic管理篇（DDL）</h2>
<h3 id="创建tocpic">创建Tocpic</h3>
<pre><code class="language-shell">./bin/kafka-topics.sh
--zookeeper CentOSA:2181,CentOSB:2181,CentOSC:2181 --create --topic topic01 --partitions 3 --replication-factor 3
</code></pre>
<h3 id="topic详细信息">Topic详细信息</h3>
<pre><code class="language-shell">./bin/kafka-topics.sh  --describe  --zookeeper CentOSA:2181,CentOSB:2181,CentOSC:2181  --topic topic01
</code></pre>
<h3 id="删除topic">删除Topic</h3>
<pre><code class="language-shell">./bin/kafka-topics.sh 
--zookeeper CentOSA:2181,CentOSB:2181,CentOSC:2181  --delete  --topic topic01
</code></pre>
<blockquote>
<p>如果用户没有配置<code>delete.topic.enable=true</code>，则Topic删除不起作用。</p>
</blockquote>
<h3 id="topic列表">Topic列表</h3>
<pre><code class="language-shell">./bin/kafka-topics.sh  --zookeeper CentOSA:2181,CentOSB:2181,CentOSC:2181  --list
</code></pre>
<h2 id="kafka-api实战jdk18">Kafka API实战(JDK1.8+)</h2>
<h3 id="快速入门">快速入门</h3>
<h4 id="maven依赖">Maven依赖</h4>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
    &lt;version&gt;2.2.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
    &lt;version&gt;1.7.25&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;log4j&lt;/groupId&gt;
    &lt;artifactId&gt;log4j&lt;/artifactId&gt;
    &lt;version&gt;1.2.17&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
    &lt;version&gt;1.7.5&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<h4 id="引入log4jproperies">引入log4j.properies</h4>
<pre><code class="language-properties">### set log levels ###
log4j.rootLogger = info,stdout 
### 输出到控制台 ###
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target = System.out
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern =%p %d %c %m %n
</code></pre>
<h4 id="在windos配置主机名和ip映射关系">在Windos配置主机名和IP映射关系</h4>
<pre><code class="language-xml">192.168.111.128 CentOSA
192.168.111.129 CentOSB
192.168.111.130 CentOSC
</code></pre>
<h4 id="生产者-2">生产者</h4>
<pre><code class="language-java">package com.msk.demo01;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.text.DecimalFormat;
import java.util.Properties;

public class KafkaProducerDemo {
    public static void main(String[] args) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        //2.创建Kafka生产者
        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);

        //3.构建ProducerRecord
        for (int i=0;i&lt;10;i++){
            DecimalFormat decimalFormat = new DecimalFormat(&quot;000&quot;);
            ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;topic04&quot;, decimalFormat.format(i), &quot;value&quot; + i);
            //4.发送消息
            producer.send(record);
        }
        //5.清空缓冲区
        producer.flush();
        //6.关闭生产者
        producer.close();
    }
}
</code></pre>
<h4 id="消费者-2">消费者</h4>
<pre><code class="language-java">package com.msk.demo01;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class KafkaConsumerDemo {
    public static void main(String[] args) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;group1&quot;);


        //2.创建Kafka消费者
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);

        //3.订阅topics
        consumer.subscribe(Arrays.asList(&quot;topic01&quot;));
        //4.死循环读取消息
        while(true){
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
            if(records!=null &amp;&amp; !records.isEmpty()){
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    int partition = record.partition();
                    long offset = record.offset();
                    long timestamp = record.timestamp();
                    String key = record.key();
                    String value = record.value();
                    System.out.println(partition+&quot;\t&quot;+offset+&quot;\t&quot;+timestamp+&quot;\t&quot;+key+&quot;\t&quot;+value);
                }
            }
        }
    }
}
</code></pre>
<h2 id="读取数据偏移量控制">读取数据偏移量控制</h2>
<p>默认当用户使用subscribe方式订阅topic消息， 默认首次offset策略是latest。当用户第一次订阅topic在消费者订阅之前的数据是无法消费到 消息的。用户可以配置消费端参数<code>auto.offset.reset</code>控制kafka消费者行为。</p>
<pre><code class="language-java">Properties props = new Properties();
props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;group1&quot;);

props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;);//默认值 latest
</code></pre>
<p>因为消费端在使用<code>consumer.poll</code>数据的时候，底层会定时的向Kafka服务器提交消费的偏移量。默认消费端的offset是自动提交的，用户如果不希望自动提交偏移量可以配置如下参数</p>
<blockquote>
<p>注意如果用户使用subscribe方式订阅topic，在消费端必须指定<code>group.id</code>，这样Kafka才能够实现消费&gt;端负载均衡以及实现组内均分组件广播。（推荐方式）</p>
</blockquote>
<p><strong>默认配置</strong></p>
<pre><code class="language-properties">enable.auto.commit	= true
auto.commit.interval.ms	= 5000
</code></pre>
<pre><code class="language-java">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,&quot;false&quot;);
</code></pre>
<p><strong>手动提交偏移量</strong></p>
<pre><code class="language-java">public class KafkaConsumerDemo {
    public static void main(String[] args) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;group1&quot;);

        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,false);
        //2.创建Kafka消费者
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);

        //3.订阅topics
        consumer.subscribe(Arrays.asList(&quot;topic01&quot;));
        //4.死循环读取消息
        while(true){
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
            if(records!=null &amp;&amp; !records.isEmpty()){
                Map&lt;TopicPartition, OffsetAndMetadata&gt; offsetMeta=new HashMap&lt;&gt;();
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    int partition = record.partition();
                    long offset = record.offset();
                    long timestamp = record.timestamp();
                    String key = record.key();
                    String value = record.value();
                    System.out.println(partition+&quot;\t&quot;+offset+&quot;\t&quot;+timestamp+&quot;\t&quot;+key+&quot;\t&quot;+value);

                    TopicPartition part = new TopicPartition(&quot;topic03&quot;, partition);
                    OffsetAndMetadata oam=new OffsetAndMetadata(offset+1);//设置下一次读取起始位置
                    offsetMeta.put(part,oam);
                }
                consumer.commitSync(offsetMeta);
            }
        }
    }
}
</code></pre>
<h2 id="指定消费分区">指定消费分区</h2>
<blockquote>
<p>通过assign方式kafka对消费者的组管理策略失效。也就是说用户可以无需配置组ID。</p>
</blockquote>
<pre><code class="language-java">public class KafkaConsumerDemo {
    public static void main(String[] args) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        
        //2.创建Kafka消费者
        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(props);

        //3.指定分区
        consumer.assign(Arrays.asList(new TopicPartition(&quot;topic01&quot;,1)));
        consumer.seek(new TopicPartition(&quot;topic01&quot;,1),1);
        //4.死循环读取消息
        while(true){
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
            if(records!=null &amp;&amp; !records.isEmpty()){
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    int partition = record.partition();
                    long offset = record.offset();
                    long timestamp = record.timestamp();
                    String key = record.key();
                    String value = record.value();
                    System.out.println(partition+&quot;\t&quot;+offset+&quot;\t&quot;+timestamp+&quot;\t&quot;+key+&quot;\t&quot;+value);
                }
            }
        }
    }
}
</code></pre>
<h2 id="kafka发送接收object">Kafka发送/接收Object</h2>
<p><strong>生产Object</strong></p>
<pre><code class="language-java">public interface Serializer&lt;T&gt; extends Closeable {
   
    void configure(Map&lt;String, ?&gt; configs, boolean isKey);
    //重点实现serialize
    byte[] serialize(String topic, T data);
    default byte[] serialize(String topic, Headers headers, T data) {
        return serialize(topic, data);
    }
    @Override
    void close();
}
</code></pre>
<p><strong>消费Object</strong></p>
<pre><code class="language-java">public interface Deserializer&lt;T&gt; extends Closeable {

    void configure(Map&lt;String, ?&gt; configs, boolean isKey);
    //重点实现方法
    T deserialize(String topic, byte[] data);
    default T deserialize(String topic, Headers headers, byte[] data) {
        return deserialize(topic, data);
    }
    @Override
    void close();
}
</code></pre>
<p><strong>实现序列化和反序列化</strong></p>
<pre><code class="language-java">public class ObjectCodec implements Deserializer&lt;Object&gt;, Serializer&lt;Object&gt; {
    @Override
    public void configure(Map&lt;String, ?&gt; configs, boolean isKey) {
        
    }

    @Override
    public byte[] serialize(String topic, Object data) {
        return SerializationUtils.serialize((Serializable) data);
    }

    @Override
    public Object deserialize(String topic, byte[] data) {
        return SerializationUtils.deserialize(data);
    }

    @Override
    public void close() {

    }
}
</code></pre>
<h2 id="生产者幂等性">生产者幂等性</h2>
<blockquote>
<p>幂等:多次操作最终的影响等价与一次操作称为幂等性操作,所有的读操作一定是幂等的.所有的写操作一定不是幂等的.当 生产者和broker默认有acks应答机制,如果当生产者发送完数据给broker之后如果没有在规定的时间内收到应答,生产者可以考虑重发数据.可以通过一下配置参数提升生产者的可靠性.</p>
</blockquote>
<pre><code class="language-properties">acks = all // 0 无需应答  n 应答个数 -1所有都需要
retries = 3 // 表示重试次数
request.timeout.ms = 3000 //等待应答超时时间
enable.idempotence = true //开启幂等性
</code></pre>
<pre><code class="language-java">public class KafkaProducerDemo {
    public static void main(String[] args) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);//等待所有从机应答
        props.put(ProducerConfig.RETRIES_CONFIG,3);//重试3次
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);//等待3s应答
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);//开启幂等性

        //2.创建Kafka生产者
        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);

        //3.构建ProducerRecord
        for (int i=15;i&lt;20;i++){
            DecimalFormat decimalFormat = new DecimalFormat(&quot;000&quot;);
            User user = new User(i, &quot;name&quot; + i, i % 2 == 0);
            ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;topic01&quot;, decimalFormat.format(i), &quot;user&quot;+i);
            //4.发送消息
            producer.send(record);
        }
        //5.清空缓冲区
        producer.flush();
        //6.关闭生产者
        producer.close();
    }
</code></pre>
<h2 id="生产者批量发送">生产者批量发送</h2>
<blockquote>
<p>生产者会尝试缓冲record，实现批量发送，通过一下配置控制发送时机，记住如果开启可batch，一定在关闭producer之前需要flush。</p>
</blockquote>
<pre><code class="language-properties">batch.size = 16384 //16KB 缓冲16kb数据本地
linger.ms = 2000 //默认逗留时间
</code></pre>
<pre><code class="language-java">public static void main(String[] args) {
    //1.配置生产者了连接属性
    Properties props = new Properties();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

    props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);
    props.put(ProducerConfig.RETRIES_CONFIG,3);
    props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);
    props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);

    props.put(ProducerConfig.BATCH_SIZE_CONFIG,1024);//1kb缓冲区
    props.put(ProducerConfig.LINGER_MS_CONFIG,1000);//设置逗留时常


    //2.创建Kafka生产者
    KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(props);

    //3.构建ProducerRecord
    for (int i=15;i&lt;20;i++){
        DecimalFormat decimalFormat = new DecimalFormat(&quot;000&quot;);
        User user = new User(i, &quot;name&quot; + i, i % 2 == 0);
        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;topic01&quot;, decimalFormat.format(i), &quot;user&quot;+i);
        //4.发送消息
        producer.send(record);
    }
    //5.清空缓冲区
    producer.flush();
    //6.关闭生产者
    producer.close();
}
</code></pre>
<h2 id="生产者事务">生产者事务</h2>
<blockquote>
<p>kafka生产者事务指的是在发送多个数据的时候，保证多个Record记录发送的原子性。如果有一条发送失败就回退，但是需要注意在使用kafka事务的时候需要调整消费者的事务隔离级别设置为<code>read_committed</code>因为kafka默认的事务隔离策略是<code>read_uncommitted</code></p>
</blockquote>
<p>开启事务</p>
<pre><code class="language-proerties">transactional.id=transaction-1 //必须保证唯一
enable.idempotence=true //开启kafka的幂等性
</code></pre>
<h3 id="只有生产者">只有生产者</h3>
<pre><code class="language-java">public class KafkaProducerDemo {
    public static void main(String[] args) {

        //1.创建Kafka生产者
        KafkaProducer&lt;String, String&gt; producer = buildKafkaProducer();

        //2.初始化事务和开启事务
        producer.initTransactions();
        producer.beginTransaction();
        try {
            for (int i=5;i&lt;10;i++){
                DecimalFormat decimalFormat = new DecimalFormat(&quot;000&quot;);
                User user = new User(i, &quot;name&quot; + i, i % 2 == 0);
                ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;(&quot;topic07&quot;, decimalFormat.format(i), &quot;user&quot;+i);
                producer.send(record);
            }
            producer.flush();
            //3.提交事务]
            producer.commitTransaction();
        } catch (Exception e) {
            System.err.println(e.getMessage());
            //终止事务
            producer.abortTransaction();
        }
        //5.关闭生产者
        producer.close();
    }

    private static KafkaProducer&lt;String, String&gt; buildKafkaProducer() {
        //0.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);

        props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);
        props.put(ProducerConfig.RETRIES_CONFIG,3);
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);

        props.put(ProducerConfig.BATCH_SIZE_CONFIG,1024);//1kb缓冲区
        props.put(ProducerConfig.LINGER_MS_CONFIG,1000);//设置逗留时常

        //开启事务
        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,&quot;transaction-&quot;+UUID.randomUUID().toString());
        return new KafkaProducer&lt;String, String&gt;(props);
    }
}
</code></pre>
<blockquote>
<p>消费者那方需要将事务隔离级别设置为`read_committed</p>
</blockquote>
<pre><code class="language-java">public class KafkaConsumerDemo {
    public static void main(String[] args) {

        //1.创建Kafka消费者
        KafkaConsumer&lt;String, String&gt; consumer = buildKafkaConsumer();

        //2.订阅topics
        consumer.subscribe(Arrays.asList(&quot;topic07&quot;));
        //3.死循环读取消息
        while(true){
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
            if(records!=null &amp;&amp; !records.isEmpty()){
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    int partition = record.partition();
                    long offset = record.offset();
                    long timestamp = record.timestamp();
                    String key = record.key();
                    String value = record.value();
                    System.out.println(partition+&quot;\t&quot;+offset+&quot;\t&quot;+timestamp+&quot;\t&quot;+key+&quot;\t&quot;+value);
                }
            }
        }
    }

    private static KafkaConsumer&lt;String, String&gt; buildKafkaConsumer() {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,&quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,&quot;group1&quot;);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;);
        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG,&quot;read_committed&quot;);
        return new KafkaConsumer&lt;String, String&gt;(props);
    }
}
</code></pre>
<h3 id="生产者消费者">生产者&amp;消费者</h3>
<pre><code class="language-java">package com.msk.demo08;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;

import java.util.Properties;
import java.util.UUID;

public class KafkaUtils {
    public static KafkaConsumer&lt;String, String&gt; buildKafkaConsumer(String servers, Class&lt;? extends Deserializer&gt; keyDeserializer,
                                                                   Class&lt;? extends Deserializer&gt; valueDeserializer,String group) {
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,servers);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,keyDeserializer);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,valueDeserializer);
        props.put(ConsumerConfig.GROUP_ID_CONFIG,group);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;);
        props.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG,&quot;read_committed&quot;);
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,false);//设置为手动提交
        return new KafkaConsumer&lt;String, String&gt;(props);
    }
    public static KafkaProducer&lt;String, String&gt; buildKafkaProducer(String servers, Class&lt;? extends Serializer&gt; keySerializer,
                                                                   Class&lt;? extends Serializer&gt; valueSerializer) {
        //1.配置生产者了连接属性
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,servers);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,keySerializer);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,valueSerializer);

        props.put(ProducerConfig.ACKS_CONFIG,&quot;all&quot;);
        props.put(ProducerConfig.RETRIES_CONFIG,3);
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,3000);
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG,true);

        props.put(ProducerConfig.BATCH_SIZE_CONFIG,1024);//1kb缓冲区
        props.put(ProducerConfig.LINGER_MS_CONFIG,1000);//设置逗留时常

        //开启事务
        props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,&quot;transaction-&quot;+ UUID.randomUUID().toString());
        return new KafkaProducer&lt;String, String&gt;(props);
    }
}
</code></pre>
<p><strong>KafkaProducerAndConsumer</strong></p>
<pre><code class="language-java">package com.msk.demo08;

import com.msk.demo05.User;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

import java.text.DecimalFormat;
import java.time.Duration;
import java.util.*;

public class KafkaProducerAndConsumer {
    public static void main(String[] args) {

        String servers = &quot;CentOSA:9092,CentOSB:9092,CentOSC:9092&quot;;
        String group=&quot;g1&quot;;
        //1.创建Kafka生产者
        KafkaProducer&lt;String, String&gt; producer = KafkaUtils.buildKafkaProducer(servers,
                StringSerializer.class, StringSerializer.class);
        KafkaConsumer&lt;String, String&gt; consumer = KafkaUtils.buildKafkaConsumer(servers,
                StringDeserializer.class, StringDeserializer.class,group);

        consumer.subscribe(Arrays.asList(&quot;topic08&quot;));
        //初始化事务
        producer.initTransactions();

        while (true) {
            producer.beginTransaction();
            ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(1));
            try {
                Map&lt;TopicPartition, OffsetAndMetadata&gt; commits = new HashMap&lt;TopicPartition, OffsetAndMetadata&gt;();
                for (ConsumerRecord&lt;String, String&gt; record : records) {
                    TopicPartition partition = new TopicPartition(record.topic(), record.partition());
                    OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(record.offset() + 1);
                    commits.put(partition, offsetAndMetadata);

                    System.out.println(record);

                    ProducerRecord&lt;String, String&gt; srecord = new ProducerRecord&lt;String, String&gt;(&quot;topic09&quot;, record.key(), record.value());
                    producer.send(srecord);
                }
                producer.flush();

                //并没使用 consumer提交，而是使用producer帮助消费者提交偏移量
                producer.sendOffsetsToTransaction(commits,group);
                //提交生产者的偏移量
                producer.commitTransaction();
            } catch (Exception e) {
                //System.err.println(e.getMessage());
                producer.abortTransaction();
            }
        }
    }
}
</code></pre>
<h2 id="springboot整合kafka">SpringBoot整合Kafka</h2>
<ul>
<li>pom.xml</li>
</ul>
<pre><code class="language-xml">&lt;properties&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;kafka.version&gt;2.2.0&lt;/kafka.version&gt;
&lt;/properties&gt;

&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;
&lt;/parent&gt;

&lt;dependencies&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;
        &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!-- kafka client处理 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
        &lt;version&gt;${kafka.version}&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<ul>
<li>application.properties</li>
</ul>
<pre><code class="language-properties">server.port=8888

# 生产者
spring.kafka.producer.bootstrap-servers=CentOSA:9092,CentOSB:9092,CentOSC:9092
spring.kafka.producer.acks=all
spring.kafka.producer.retries=1
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# 消费者
spring.kafka.consumer.bootstrap-servers=CentOSA:9092,CentOSB:9092,CentOSC:9092
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
</code></pre>
<ul>
<li>代码</li>
</ul>
<pre><code class="language-java">@SpringBootApplication
@EnableScheduling
public class KafkaApplicationDemo {
    @Autowired
    private KafkaTemplate kafkaTemplate;

    public static void main(String[] args) {
        SpringApplication.run(KafkaApplicationDemo.class,args);
    }
    @Scheduled(cron = &quot;0/1 * * * * ?&quot;)
    public void send(){
        String[] message=new String[]{&quot;this is a demo&quot;,&quot;hello world&quot;,&quot;hello boy&quot;};
        ListenableFuture future = kafkaTemplate.send(&quot;topic07&quot;, message[new Random().nextInt(message.length)]);
        future.addCallback(o -&gt; System.out.println(&quot;send-消息发送成功：&quot; + message), throwable -&gt; System.out.println(&quot;消息发送失败：&quot; + message));
    }

    @KafkaListener(topics = &quot;topic07&quot;,id=&quot;g1&quot;)
    public void processMessage(ConsumerRecord&lt;?, ?&gt; record) {
        System.out.println(&quot;record:&quot;+record);
    }
}
</code></pre>

						</div>
						<div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      个人博客
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://mask0407.github.io/kafka00/" title="一篇文章读懂Kafka消息队列">https://mask0407.github.io/kafka00/</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外,转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://mask0407.github.io/wCHLQOml4/"># Kafka</a>
    
      <a href="https://mask0407.github.io/mWPQYQko7/"># Hadoop</a>
    
      <a href="https://mask0407.github.io/1ffDVERZml/"># 大数据</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="iconfont icon-angle_left"></i>
        <a class="nav-pc-next" href="https://mask0407.github.io/storm00/">Storm 运行jar出错:org.apache.storm.thrift.TApplicationException: getLeader failed: unknownre result</a class="nav-pc-next">
        <a class="nav-mobile-prev" href="https://mask0407.github.io/storm00/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" href="https://mask0407.github.io/flume01/">Flume 介绍与使用</a>
        <a class="nav-mobile-next" href="https://mask0407.github.io/flume01/">下一篇</a>
        <i class="iconfont icon-angle_right"></i>
      
    </div>
  </div>
</div>
						
						<div class="comment"></div>
					</section>

				</div>
				<div class="sidebar">
    <div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">关于博主</p>
    <img class="site-author-image" src="https://mask0407.github.io/images/avatar.png"/>
    <p class="site-description">Memory</p>
    <p class="site-description">温故而知新</p>
  </div>
  <div class="sidebar-item side-item-stat">
    <div class="sidebar-item-box">
      <a href="/archives/">
        <span class="site-item-stat-count">34</span>
        <span class="site-item-stat-name">日志</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name">标签</span>
      </a>
    </div>
  </div>
  <div class="sidebar-item">
    <span class="site-item-rss">
        <i class="iconfont icon-rss"></i>
        <a href="https://mask0407.github.io/atom.xml" target="_blank">RSS</a>
    </span>
  </div>
  <div class="sidebar-item sidebar-item-social">
    <div class="social-item">
      <a href="https://www.github.com/memorypro">
        <i class="iconfont icon-github"></i> GitHub
      </a>
      <a href="">
        <i class="iconfont icon-twitter"></i> Twitter
      </a>
    </div>
    <div class="social-item">
      <a href="">
        <i class="iconfont icon-globe"></i> 豆瓣
      </a>
      <a href="">
        <i class="iconfont icon-globe"></i> 知乎
      </a>
    </div>
  </div>
</div>

<div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">文章分类</p>
  </div>
  <div>
    <ul class="site-meta-tags">
      
        <li >
          <a  href="https://mask0407.github.io/-GjvL3Wxg/">
            算法
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rmtSLWko1/">
            java
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/WwvK-h-X5/">
            机器学习
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/aAuqPKSPG/">
            Spark
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/1ffDVERZml/">
            大数据
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/vIyAknLKTN/">
            线程
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/NcOh8FcvU/">
            NoSql
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/b_rV1mTAIK/">
            Redis
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/77iES6Gqn/">
            Docker
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/zTsEErFnpM/">
            GreenPlum
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/uyhs3Xoe6/">
            SpringCloud
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rg_9e-j4YM/">
            微服务
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/F5ekRJs32/">
            Elasticsearch
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/8sXwjdxU1/">
            Storm
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/wCHLQOml4/">
            Kafka
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/mWPQYQko7/">
            Hadoop
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/QZpGpA6c1/">
            Flume
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/yn_9TWp8Z/">
            Hive
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/-ElJdKXRJ/">
            Hbase
          </a>
        </li>

      
    </ul>
     
  </div>

</div>


<div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">友情链接</p>
  </div>
  <div class="social-item">
    <ul style=" list-style: none; margin-left: -10px;" >
    
      
        <li >
          <a  href="https://mask0407.github.io/-GjvL3Wxg/">
            算法
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rmtSLWko1/">
            java
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/WwvK-h-X5/">
            机器学习
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/aAuqPKSPG/">
            Spark
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/1ffDVERZml/">
            大数据
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/vIyAknLKTN/">
            线程
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/NcOh8FcvU/">
            NoSql
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/b_rV1mTAIK/">
            Redis
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/77iES6Gqn/">
            Docker
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/zTsEErFnpM/">
            GreenPlum
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/uyhs3Xoe6/">
            SpringCloud
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rg_9e-j4YM/">
            微服务
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/F5ekRJs32/">
            Elasticsearch
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/8sXwjdxU1/">
            Storm
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/wCHLQOml4/">
            Kafka
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/mWPQYQko7/">
            Hadoop
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/QZpGpA6c1/">
            Flume
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/yn_9TWp8Z/">
            Hive
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/-ElJdKXRJ/">
            Hbase
          </a>
        </li>

      

      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>

    </ul>
     
  </div>

</div>

</div>
				<!-- 
<div class="sidebar">
    <div class="sidebar-wrapper" id="sidebar">
      
        <div class="post-list-sidebar">
          <div class="sidebar-title">
            <span id="tocSideBar" class="sidebar-title-item sidebar-title-active">文章目录</span>
            <span id="metaSideBar" class="sidebar-title-item">站点概览</span>
          </div>
        </div>
      
      <div class="sidebar-body" id="sidebar_body">
        
          <div class="post-side-meta" id="post_side_meta">
            <div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">关于博主</p>
    <img class="site-author-image" src="https://mask0407.github.io/images/avatar.png"/>
    <p class="site-description">Memory</p>
    <p class="site-description">温故而知新</p>
  </div>
  <div class="sidebar-item side-item-stat">
    <div class="sidebar-item-box">
      <a href="/archives/">
        <span class="site-item-stat-count">34</span>
        <span class="site-item-stat-name">日志</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">19</span>
        <span class="site-item-stat-name">标签</span>
      </a>
    </div>
  </div>
  <div class="sidebar-item">
    <span class="site-item-rss">
        <i class="iconfont icon-rss"></i>
        <a href="https://mask0407.github.io/atom.xml" target="_blank">RSS</a>
    </span>
  </div>
  <div class="sidebar-item sidebar-item-social">
    <div class="social-item">
      <a href="https://www.github.com/memorypro">
        <i class="iconfont icon-github"></i> GitHub
      </a>
      <a href="">
        <i class="iconfont icon-twitter"></i> Twitter
      </a>
    </div>
    <div class="social-item">
      <a href="">
        <i class="iconfont icon-globe"></i> 豆瓣
      </a>
      <a href="">
        <i class="iconfont icon-globe"></i> 知乎
      </a>
    </div>
  </div>
</div>

<div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">文章分类</p>
  </div>
  <div>
    <ul class="site-meta-tags">
      
        <li >
          <a  href="https://mask0407.github.io/-GjvL3Wxg/">
            算法
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rmtSLWko1/">
            java
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/WwvK-h-X5/">
            机器学习
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/aAuqPKSPG/">
            Spark
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/1ffDVERZml/">
            大数据
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/vIyAknLKTN/">
            线程
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/NcOh8FcvU/">
            NoSql
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/b_rV1mTAIK/">
            Redis
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/77iES6Gqn/">
            Docker
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/zTsEErFnpM/">
            GreenPlum
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/uyhs3Xoe6/">
            SpringCloud
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rg_9e-j4YM/">
            微服务
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/F5ekRJs32/">
            Elasticsearch
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/8sXwjdxU1/">
            Storm
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/wCHLQOml4/">
            Kafka
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/mWPQYQko7/">
            Hadoop
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/QZpGpA6c1/">
            Flume
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/yn_9TWp8Z/">
            Hive
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/-ElJdKXRJ/">
            Hbase
          </a>
        </li>

      
    </ul>
     
  </div>

</div>


<div class="sidebar-wrapper">
  <div class="sidebar-item">
    <p class="site-author-name">友情链接</p>
  </div>
  <div class="social-item">
    <ul style=" list-style: none; margin-left: -10px;" >
    
      
        <li >
          <a  href="https://mask0407.github.io/-GjvL3Wxg/">
            算法
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rmtSLWko1/">
            java
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/WwvK-h-X5/">
            机器学习
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/aAuqPKSPG/">
            Spark
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/1ffDVERZml/">
            大数据
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/vIyAknLKTN/">
            线程
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/NcOh8FcvU/">
            NoSql
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/b_rV1mTAIK/">
            Redis
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/77iES6Gqn/">
            Docker
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/zTsEErFnpM/">
            GreenPlum
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/uyhs3Xoe6/">
            SpringCloud
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/rg_9e-j4YM/">
            微服务
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/F5ekRJs32/">
            Elasticsearch
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/8sXwjdxU1/">
            Storm
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/wCHLQOml4/">
            Kafka
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/mWPQYQko7/">
            Hadoop
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/QZpGpA6c1/">
            Flume
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/yn_9TWp8Z/">
            Hive
          </a>
        </li>

      
        <li >
          <a  href="https://mask0407.github.io/-ElJdKXRJ/">
            Hbase
          </a>
        </li>

      

      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>
      <li > <a  href="">链接1</a></li>

    </ul>
     
  </div>

</div>

          </div>
          <div class="post-toc sidebar-body-active" id="post_toc" style="opacity: 1;">
            <div class="toc-box">
  <div class="toc-wrapper" id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E6%A6%82%E5%BF%B5">消息队列的概念</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90">使用消息队列的场景分析</a>
<ul>
<li><a href="#%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81">异步消息发送：</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E9%97%B4%E8%A7%A3%E8%80%A6%E5%90%88">系统间解耦合</a></li>
</ul>
</li>
<li><a href="#kafka-%E6%9E%B6%E6%9E%84">Kafka 架构</a></li>
<li><a href="#kafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85">Kafka集群安装</a>
<ul>
<li><a href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">准备工作</a></li>
<li><a href="#%E5%AE%89%E8%A3%85zookeeper%E9%9B%86%E7%BE%A4%E7%A1%AE%E4%BF%9Dkafka%E9%9B%86%E7%BE%A4%E7%9A%84%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C">安装Zookeeper集群确保Kafka集群的正常运行</a></li>
<li><a href="#kafka%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4">Kafka安装步骤</a></li>
<li><a href="#%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1">启动服务</a></li>
<li><a href="#%E6%B5%8B%E8%AF%95">测试</a></li>
</ul>
</li>
<li><a href="#topic-%E5%92%8C-%E6%97%A5%E5%BF%97">Topic 和 日志</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85">生产者</a></li>
<li><a href="#%E6%B6%88%E8%B4%B9%E8%80%85">消费者</a></li>
<li><a href="#topic%E7%AE%A1%E7%90%86%E7%AF%87ddl">Topic管理篇（DDL）</a>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BAtocpic">创建Tocpic</a></li>
<li><a href="#topic%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF">Topic详细信息</a></li>
<li><a href="#%E5%88%A0%E9%99%A4topic">删除Topic</a></li>
<li><a href="#topic%E5%88%97%E8%A1%A8">Topic列表</a></li>
</ul>
</li>
<li><a href="#kafka-api%E5%AE%9E%E6%88%98jdk18">Kafka API实战(JDK1.8+)</a>
<ul>
<li><a href="#%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8">快速入门</a>
<ul>
<li><a href="#maven%E4%BE%9D%E8%B5%96">Maven依赖</a></li>
<li><a href="#%E5%BC%95%E5%85%A5log4jproperies">引入log4j.properies</a></li>
<li><a href="#%E5%9C%A8windos%E9%85%8D%E7%BD%AE%E4%B8%BB%E6%9C%BA%E5%90%8D%E5%92%8Cip%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB">在Windos配置主机名和IP映射关系</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85-2">生产者</a></li>
<li><a href="#%E6%B6%88%E8%B4%B9%E8%80%85-2">消费者</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E5%81%8F%E7%A7%BB%E9%87%8F%E6%8E%A7%E5%88%B6">读取数据偏移量控制</a></li>
<li><a href="#%E6%8C%87%E5%AE%9A%E6%B6%88%E8%B4%B9%E5%88%86%E5%8C%BA">指定消费分区</a></li>
<li><a href="#kafka%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6object">Kafka发送/接收Object</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%B9%82%E7%AD%89%E6%80%A7">生产者幂等性</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%89%B9%E9%87%8F%E5%8F%91%E9%80%81">生产者批量发送</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1">生产者事务</a>
<ul>
<li><a href="#%E5%8F%AA%E6%9C%89%E7%94%9F%E4%BA%A7%E8%80%85">只有生产者</a></li>
<li><a href="#%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85">生产者&amp;消费者</a></li>
</ul>
</li>
<li><a href="#springboot%E6%95%B4%E5%90%88kafka">SpringBoot整合Kafka</a></li>
</ul>
</li>
</ul>

  </div>
</div>

<script>

let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1; 
let active = 'active-show', activeClass = 'active-current';
let tocWrapper = document.querySelector('#toc_wrapper');
let tocContent = tocWrapper.children[0];

function addTocNumber(elem, deep) {
  if (!elem) {
    return;
  }
  let prop = elem.__proto__;

  if (prop === HTMLUListElement.prototype) {
    for (let i = 0; i < elem.children.length; i++) {
      addTocNumber(elem.children[i], deep + (i + 1) + '.');
    }
  } else if (prop === HTMLLIElement.prototype) {
    // 保存li元素
    lList.push(elem);
    for (let i = 0; i < elem.children.length; i++) {
      let cur = elem.children[i];
      if (cur.__proto__ === HTMLAnchorElement.prototype) {
        cur.text =  deep + ' ' + cur.text;
      } else if (cur.__proto__ === HTMLUListElement.prototype) {
        addTocNumber(cur, deep);
      }
    }
  }
}


document.addEventListener('scroll', function(e) {
  if (lList.length <= 0) {
    return;
  }
  let scrollTop = document.body.scrollTop;
  let dir;

  if (lastTop - scrollTop > 0) {
    dir = 'up';
  } else {
    dir = 'down';
  }

  lastTop = scrollTop;
  if (scrollTop <= 0) {
    if (lastIndex >= 0 && lastIndex < hList.length) {
      lList[lastIndex].classList.remove(activeClass);
    }
    return;
  }

  let current = 0, hasFind = false;
  for (let i = 0; i < hList.length; i++) {
    if (hList[i].offsetTop > scrollTop) {
      current = i;
      hasFind = true;
      break;
    }
  }
  if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
    current = hList.length - 1;
  } else {
    current--;
  }
  if (dir === 'down') {
    if (current > lastIndex) {
      addActiveClass(current);
      removeActiveClass(lastIndex) 
      lastIndex = current;
      removeParentActiveClass();
      lList[current] && addActiveLiElemment(lList[current].parentElement,tocContent);
    }
  } else {
    if (current < lastIndex) {
      addActiveClass(current);
      removeActiveClass(lastIndex);
      lastIndex = current;
      removeParentActiveClass();
      lList[current] && addActiveLiElemment(lList[current].parentElement,tocContent);
    }
  }
});

function removeParentActiveClass() {
  let parents = tocContent.querySelectorAll('.'+active)
  parents.forEach(function(elem) {
    elem.classList.remove(active);
  });
}

function addActiveClass(index) {
  if (index >= 0 && index < hList.length) {
    lList[index].classList.add(activeClass);
  }
}

function removeActiveClass(index) {
  if (index >= 0 && index < hList.length) {
    lList[index].classList.remove(activeClass);
  }
}

function addActiveLiElemment(elem, parent) {
  if (!elem || elem === parent) {
    return;
  } else {
    if (elem.__proto__ === HTMLLIElement.prototype) {
      elem.classList.add(active);
    }
    addActiveLiElemment(elem.parentElement, parent);
  }
}

function showToc() {
  if (tocWrapper) {
    postBody = document.querySelector('#post_body');
    for (let i = 0; i < postBody.children.length; i++) {
      if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
        hList.push(postBody.children[i]);
      }
    }

    if (hList.length > 10) {
      active = 'active-hidden'
      tocContent.classList.add('closed');
    } else {
      tocContent.classList.add('expanded');
    }
  }
}
addTocNumber(tocContent, '');

window.addEventListener('load', function() {
  showToc();
  document.querySelector('#sidebar').style='display: block;';
  tocWrapper.classList.add('toc-active');
  setTimeout(function() {
    if ("createEvent" in document) {
      let evt = document.createEvent("HTMLEvents");
      evt.initEvent("scroll", false, true);
      document.dispatchEvent(evt);
    }
    else {
      document.fireEvent("scroll");
    }
  }, 500)
})

</script>
          </div>
        
      </div>
    </div>
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    window.Velocity(hideElement, 'stop');
    window.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        window.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);

  }

  postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  let limitTop = sidebar.offsetTop;
  let hasFix = false;
  window.addEventListener('scroll', function(e) {
    if (document.body.scrollTop >= limitTop) {
      if (!hasFix) {
        sidebar.classList.add('sidebar-fixed');
        hasFix = true;
      }
    } else {
      if (hasFix) {
        sidebar.classList.remove('sidebar-fixed');
        hasFix = false;
      }
    }
  });
</script> -->
				<!-- </div> -->
			</div>

		</div>
		<div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      © 2019-2020 <i class="iconfont icon-heart"></i> Memory
    </div>
    <div class="poweredby">
      <div class="power-left">Power By<a href="https://github.com/memorypro/"> Memory</a></div>
      <div>Copy<a href="https://github.com/hsxyhao/gridea-theme-next"> Gridea NexT Theme</a></div>
      <div>Copy<a href="https://github.com/iissnan/hexo-theme-next"> Hexo Next Theme</a></div>
    </div>
  </footer>
  <div class="back-to-top" id="back_to_top">
    <i class="iconfont icon-arrow_up"></i>
    <span class="scrollpercent">
      <span id="back_to_top_text">100</span>%
    </span>
  </div>
</div>

<script>

  let body = document.body;

  let back2Top = document.querySelector('#back_to_top'),
  back2TopText = document.querySelector('#back_to_top_text');

  function scrollAnimation(currentY, targetY) {
   
    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function(e) {
    scrollAnimation(body.scrollTop, 0);
    e.stopPropagation();
    return false;
  });
  
  window.addEventListener('scroll', function(e) {
    let percent = body.scrollTop / (body.scrollHeight - body.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    back2TopText.textContent = Math.floor(percent);
  });

  // 代码高亮
  hljs.initHighlightingOnLoad();
</script>

	</div>
	<!--载入js，在</body>之前插入即可-->
	<!--Leancloud 操作库:-->
	<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
	<!--Valine 的核心代码库-->
	<script src="/media/scripts/Valine.min.js"></script>

	<script>
		
		var uid = 'Xlp2Ds9RnJWmyyC4uAz8fQKM-gzGzoHsz' 
		var ukey = 'i8YPcgwSlB5my4RQsxvntlG8' 
		new Valine({
			// AV 对象来自上面引入av-min.js(老司机们不要开车➳♡゛扎心了老铁)
			av: AV,
			el: '.comment',
			lang: 'zh-cn',//设置评论语言
			emoticon_url: 'https://cloud.panjunwen.com/alu',
			emoticon_list: ["狂汗.png", "不说话.png", "汗.png", "坐等.png", "献花.png", "不高兴.png", "中刀.png", "害羞.png", "皱眉.png", "小眼睛.png", "暗地观察.png"],
			app_id:uid,
			app_key: ukey,
			placeholder: '评论留言'
		});
	</script>

</body>
<script src="/media/js/motion.js"></script>

</html>